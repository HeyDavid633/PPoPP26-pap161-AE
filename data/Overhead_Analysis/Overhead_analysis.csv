Batch Size,Sequence Length,Model,Analytical Model,Hash Encoding,Numercial Decoding,Reward Algorithm,STOF
1,128,Bert-base,13.39,76.053,114.08,285.199,23300.0
1,128,Bert-large,3.609,107.24,160.86,402.15,22600.0
1,128,GPT-2,3.608,79.826,119.739,299.347,23800.0
1,128,LLaMA,3.669,71.391,107.086,267.716,29500.0
1,128,T5,3.583,160.482,240.724,601.809,43100.0
1,128,ViT,3.611,72.811,109.216,273.041,93900.0
8,512,Bert-base,7.423,77.082,115.622,289.056,40900.0
8,512,Bert-large,7.471,142.145,213.217,533.042,55000.0
8,512,GPT-2,7.404,65.226,97.839,244.597,40900.0
8,512,LLaMA,7.414,101.194,151.791,379.478,43600.0
8,512,T5,7.428,96.142,144.213,360.532,80300.0
8,512,ViT,7.447,75.128,112.692,281.73,99300.0
16,2048,Bert-base,87.881,99.701,149.552,373.879,99600.0
16,2048,Bert-large,76.479,78.801,118.202,295.504,225300.0
16,2048,GPT-2,71.064,86.585,129.877,324.693,122200.0
16,2048,LLaMA,72.21,93.728,140.593,351.482,246600.0
16,2048,T5,75.777,115.894,173.84,434.601,388300.0
16,2048,ViT,74.408,83.285,124.928,312.32,412800.0
