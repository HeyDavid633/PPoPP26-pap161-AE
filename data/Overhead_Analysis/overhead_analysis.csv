Batch Size,Sequence Length,Model,Analytical Model,Hash Encoding,Numercial Decoding,Reward Algorithm,STOF
1,128,Bert-base, 6.47, 98.182, 111.971, 434.136, 23350
1,128,Bert-large, 6.47, 84.234, 101.62, 420.392, 22610
1,128,GPT-2, 6.46, 80.112, 102.68, 500.937, 23870
1,128,LLaMA, 6.69, 132.276, 198.414, 496.034, 29450
1,128,T5, 6.42, 105.138, 120.464, 561.9, 43100
1,128,ViT, 9.57, 222.884, 334.326,835.816, 93910
8,512,Bert-base, 9.75, 75.138, 70.464, 427.483, 34910
8,512,Bert-large, 10.84, 85.43, 90.583, 395.578, 35040
8,512,GPT-2, 9.76, 97.73, 107.502, 427.483, 34980
8,512,LLaMA, 9.040, 117.195, 115.793, 439.483, 43620
8,512,T5, 10.5, 211.875, 239.744, 550.274, 62300
8,512,ViT, 9.2, 260.158, 240.237, 860.593, 99330
16,2048,Bert-base, 60.98, 121.608, 162.614, 549.715, 36970
16,2048,Bert-large, 64.68, 86.823, 83.48, 480.858, 41320
16,2048,GPT-2, 82.89, 82.047, 109.348, 428.268, 33240
16,2048,LLaMA, 91.680, 761.473, 624.709, 4661.772, 264560
16,2048,T5, 64.08, 146.838, 181.14, 583.905, 90360
16,2048,ViT, 136.492, 714.523, 721.785, 6804.463, 412820